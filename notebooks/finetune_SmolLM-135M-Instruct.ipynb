{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970cac83-6ee7-46d3-9150-cdfbb8c62825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from trl import DataCollatorForCompletionOnlyLM, SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d539a-ed18-4c42-82d9-91b4a56bb915",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"HuggingFaceTB/SmolLM-135M-Instruct\"\n",
    "dataset_id = \"medalpaca/medical_meadow_medical_flashcards\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d406930a-db0f-4252-90db-36dcab539e3b",
   "metadata": {},
   "source": [
    "## Preparing and Formatting the Dataset for Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c731a37-a44a-4d8f-b66b-3009b8b1ca19",
   "metadata": {},
   "source": [
    "We'll be preparing a dataset for training a Language Model (LLM). The steps involve formatting the dataset to keep only the necessary columns and splitting it into training and evaluation sets. Proper dataset preparation is crucial for ensuring the model's effectiveness and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78a68e5-7d84-49d5-956d-7507c9348aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(dataset, keys, instruction_col_name, response_col_name):\n",
    "    \"\"\"Format the dataset by retaining only necessary columns and renaming them.\"\"\"\n",
    "    cols_to_remove = [key for key in keys if key not in [instruction_col_name, response_col_name]]\n",
    "    dataset = dataset.remove_columns(cols_to_remove)\n",
    "    dataset = dataset.rename_column(instruction_col_name, \"instruction\")\n",
    "    dataset = dataset.rename_column(response_col_name, \"response\")\n",
    "    return dataset\n",
    "    \n",
    "def prepare_datasets(dataset, instruction_col_name, response_col_name):\n",
    "    \"\"\"Format and split the dataset for training and evaluation.\"\"\"\n",
    "    available_cols = list(dataset[\"train\"].features.keys())\n",
    "    formatted_dataset = format_dataset(\n",
    "        dataset, available_cols, instruction_col_name, response_col_name\n",
    "    )\n",
    "\n",
    "    if \"valid\" in formatted_dataset:\n",
    "        train_dataset = formatted_dataset[\"train\"]\n",
    "        eval_dataset = formatted_dataset[\"valid\"]\n",
    "    elif \"test\" in formatted_dataset:\n",
    "        train_dataset = formatted_dataset[\"train\"]\n",
    "        eval_dataset = formatted_dataset[\"test\"]\n",
    "    else:\n",
    "        split_dataset = formatted_dataset[\"train\"].train_test_split(test_size=0.2)\n",
    "        train_dataset, eval_dataset = split_dataset[\"train\"], split_dataset[\"test\"]\n",
    "\n",
    "    return train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2bc16-9a88-4d48-8794-b1a618d69ebc",
   "metadata": {},
   "source": [
    "load the dataset using its ID or path. This dataset will be used for training and evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dfcaf0-5933-49a4-90b2-0048031ea1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc2617-3b3b-4b46-9e82-812f3474ae3f",
   "metadata": {},
   "source": [
    "Print the dataset information to inspect its structure and column names. This is important to understand the data we're working with and ensure that we correctly identify the columns containing the `instructions` and `responses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9f068-3158-406b-82a3-4805fd11e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6ffd0-faa3-44b6-b632-2a2b3eb68ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c514831-eb06-45c6-8515-7783bb35b786",
   "metadata": {},
   "source": [
    "Format the dataset and split it into training and evaluation sets. Here, `input` and `output` represent the columns in the dataset holding the `instruction` and `response`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9940c83-307d-434c-8dd1-861bdde95c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, eval_dataset = prepare_datasets(\n",
    "    dataset, instruction_col_name=\"input\", response_col_name=\"output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd8c715-6389-4198-a24d-a06638f0761a",
   "metadata": {},
   "source": [
    "Ensures that all previous operations have been executed as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0731dab-a7fb-4dfe-88da-3e323c73c5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{train_dataset = }\")\n",
    "print(f\"{eval_dataset = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5485a205-c974-41fe-b1a6-3aeb73c5bc2a",
   "metadata": {},
   "source": [
    "## Load and Test Pre-trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eedf1fa-82d1-4ea2-bc82-3f6b627f77f3",
   "metadata": {},
   "source": [
    "Define Functions for Response Generation and Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42f042-b8aa-4acf-b627-6ebec3c45529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, tokenizer, instruction, device=\"cpu\"):\n",
    "    \"\"\"Generate a response from the model based on an instruction.\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": instruction}]\n",
    "    input_text = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(\n",
    "        inputs, max_new_tokens=128, temperature=0.2, top_p=0.9, do_sample=True\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "def print_example(example):\n",
    "    \"\"\"Print an example from the dataset.\"\"\"\n",
    "    print(f\"Original Dataset Example:\")\n",
    "    print(f\"Instruction: {example['instruction']}\")\n",
    "    print(f\"Response: {example['response']}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "def print_response(response):\n",
    "    \"\"\"Print the model's response.\"\"\"\n",
    "    print(f\"Model response:\")\n",
    "    print(response.split(\"assistant\\n\")[-1])\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b5e745-c0dd-4a36-8a68-a64ea320cb41",
   "metadata": {},
   "source": [
    "Load the Model, and the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df21a3b-0a48-493b-94ef-fe78e0ecbfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f8fe5-edc4-4f3b-9b71-2ba2480f641b",
   "metadata": {},
   "source": [
    "#### Test the Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee37bc-5569-4ea6-881a-5d1f446e8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a test example\n",
    "example1 = eval_dataset[1]\n",
    "\n",
    "response = generate_response(model, tokenizer, example1[\"instruction\"], device)\n",
    "\n",
    "print_example(example1)\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2b33c2-450b-46fd-bf8b-69da982eaf01",
   "metadata": {},
   "source": [
    "### Supervised Fine-tuning Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fac947-763c-485d-93f5-50a9352c3a91",
   "metadata": {},
   "source": [
    "#### Training adapters [Read More](https://huggingface.co/docs/trl/v0.9.6/en/sft_trainer#training-adapters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a169bbde-308b-4e1b-a06d-6a52049b18c1",
   "metadata": {},
   "source": [
    "Huggingface support tight integration with ðŸ¤— PEFT library so that we can conveniently train adapters instead of training the entire model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1676b8-564b-4f7e-a23b-199aec004447",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b3660a-b68c-425c-9e97-1fafb617ebe4",
   "metadata": {},
   "source": [
    "#### Customize prompts using packed dataset [Read More](https://huggingface.co/docs/trl/en/sft_trainer#customize-your-prompts-using-packed-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf087581-4241-40ef-ba11-11f765192cb5",
   "metadata": {},
   "source": [
    "Since our dataset has two field `instruction` and `response`, we need to combine them as one string to be able to past it to the SFT Trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d744f01-6fdf-4a31-897a-c6bab97655d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(example: dict) -> str:\n",
    "    \"\"\"Format prompt for training.\"\"\"\n",
    "    text = f\"<|im_start|>user\\n{example['instruction']}<|im_end|>\\n<|im_start|>assistant\\n{example['response']}<|im_end|>\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68970af9-9cd8-4ea4-ac07-1e31bd31a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 5\n",
    "\n",
    "output_dir = f\"{model_id.split('/')[-1]}-{dataset_id.split('/')[-1]}-{num_train_epochs}epochs\"\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    max_seq_length=512,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=500,  # save checkpoints every n training steps\n",
    "    logging_steps=500,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    warmup_ratio=0.05,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    packing=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    peft_config=peft_config,\n",
    "    args=sft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b6e793-2efb-4659-b72c-c5446c5e4d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f65fea-9d6e-44bb-b675-2e47f2cce083",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe691f4-b4b3-409e-adf5-94bb664d9e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f5fb5-df6f-4f50-ae25-31283f85acbc",
   "metadata": {},
   "source": [
    "#### Test Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c055c3a-45f7-455b-8832-b710248e0e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = AutoModelForCausalLM.from_pretrained(output_dir).to(device)\n",
    "\n",
    "response = generate_response(ft_model, tokenizer, example1[\"instruction\"], device)\n",
    "\n",
    "print_example(example1)\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c8d914-6b4f-4488-88be-7c856f92114a",
   "metadata": {},
   "source": [
    "#### Push the fine-tuned model to your HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705dced-c8cc-41d7-8a58-d198b9eed9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_access_token = \"\"\n",
    "if hf_access_token:\n",
    "    trainer.push_to_hub(token=hf_access_token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
